{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3cee56ccea244fbdb90c8c12ca8c31e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07e00e9ff1de494fb4c2af9f4fa1a172",
              "IPY_MODEL_960148996d8140ec9348236eff18c83b",
              "IPY_MODEL_808aa02bbbf7469799a63d2d997ededf"
            ],
            "layout": "IPY_MODEL_3ed116b41fc644d9b3f2ae414bf073ac"
          }
        },
        "07e00e9ff1de494fb4c2af9f4fa1a172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_282b24f5b2924cf6a3f0fc8364d6186a",
            "placeholder": "​",
            "style": "IPY_MODEL_f820952b20c449c79b2c6e86bf586156",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "960148996d8140ec9348236eff18c83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ab8030100af40e29b4d654cb6d6aaac",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0eaef979ef547dfa71693a83c9aa877",
            "value": 48
          }
        },
        "808aa02bbbf7469799a63d2d997ededf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1719717c8ff41c68f56bb011b8eda8c",
            "placeholder": "​",
            "style": "IPY_MODEL_8c622109de814c9486c37c2a92fc5a6b",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.46kB/s]"
          }
        },
        "3ed116b41fc644d9b3f2ae414bf073ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "282b24f5b2924cf6a3f0fc8364d6186a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f820952b20c449c79b2c6e86bf586156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ab8030100af40e29b4d654cb6d6aaac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0eaef979ef547dfa71693a83c9aa877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1719717c8ff41c68f56bb011b8eda8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c622109de814c9486c37c2a92fc5a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f89f12e72e9649caad35020afe44ecdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e5d54acf3d046409c5c17c6e11f13d7",
              "IPY_MODEL_b9ca3b3642a0417b93017099c685fbee",
              "IPY_MODEL_770f0a2dbcd74fd0a57d9ae80eda4409"
            ],
            "layout": "IPY_MODEL_60dd58759dda45f48fbf111dc0b30ffc"
          }
        },
        "1e5d54acf3d046409c5c17c6e11f13d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36b1f47c3bb0463c81e86bfb9ecef7cf",
            "placeholder": "​",
            "style": "IPY_MODEL_66300d4af5984221866ba2811d1dbc8a",
            "value": "vocab.txt: 100%"
          }
        },
        "b9ca3b3642a0417b93017099c685fbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8224a274ff14140ba28622277eb229c",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7d6f31c3fdb43779ffc39c6273a5e00",
            "value": 231508
          }
        },
        "770f0a2dbcd74fd0a57d9ae80eda4409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5840d6b15d64f93bacc65c4af9c6ffe",
            "placeholder": "​",
            "style": "IPY_MODEL_c5bb20c54c034eb199017a07af385f32",
            "value": " 232k/232k [00:00&lt;00:00, 5.34MB/s]"
          }
        },
        "60dd58759dda45f48fbf111dc0b30ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b1f47c3bb0463c81e86bfb9ecef7cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66300d4af5984221866ba2811d1dbc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8224a274ff14140ba28622277eb229c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d6f31c3fdb43779ffc39c6273a5e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5840d6b15d64f93bacc65c4af9c6ffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5bb20c54c034eb199017a07af385f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c09edb6dfab5492e91d0227063cbeef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ef63ccab6f3418288b9599d5ae218b9",
              "IPY_MODEL_80315584e3f9402d875a34faea743a96",
              "IPY_MODEL_dcb4427ce06c483ca55b570276eb8f61"
            ],
            "layout": "IPY_MODEL_bda660faa6a34818b3061b01cfca9256"
          }
        },
        "5ef63ccab6f3418288b9599d5ae218b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fb5c565374048758a084f2cfd3cff3f",
            "placeholder": "​",
            "style": "IPY_MODEL_0e56dc25d06842909c0112cc4fc88950",
            "value": "tokenizer.json: 100%"
          }
        },
        "80315584e3f9402d875a34faea743a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cf7fcb785a541b2a309278b6ce28c12",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_552e8714139047e787ed364d40f74885",
            "value": 466062
          }
        },
        "dcb4427ce06c483ca55b570276eb8f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea3c0b8a614e4b0cada981d66740a1f3",
            "placeholder": "​",
            "style": "IPY_MODEL_204f26920dd44cbeb4459086fae83a74",
            "value": " 466k/466k [00:00&lt;00:00, 19.3MB/s]"
          }
        },
        "bda660faa6a34818b3061b01cfca9256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fb5c565374048758a084f2cfd3cff3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e56dc25d06842909c0112cc4fc88950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cf7fcb785a541b2a309278b6ce28c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "552e8714139047e787ed364d40f74885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea3c0b8a614e4b0cada981d66740a1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "204f26920dd44cbeb4459086fae83a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "971583f22e5b413a9a0eed60daa5ef61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_261f9fb870b84462ba5732ca6e7a8022",
              "IPY_MODEL_3f8f7ecf1b1e4fd0b457f61e51b7c9c4",
              "IPY_MODEL_aa54731512744c2fa15585448ab8a6c7"
            ],
            "layout": "IPY_MODEL_0c814c629d8d4c1cb801873f35158954"
          }
        },
        "261f9fb870b84462ba5732ca6e7a8022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eb2161de6f94cf0bd94d46c3f5c9687",
            "placeholder": "​",
            "style": "IPY_MODEL_7f5d94f21d9a4c41ae48f647f94c1448",
            "value": "config.json: 100%"
          }
        },
        "3f8f7ecf1b1e4fd0b457f61e51b7c9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d684a312c7c42c69c48936a2a37b3b4",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3383527d075940d289414108a5a619cb",
            "value": 570
          }
        },
        "aa54731512744c2fa15585448ab8a6c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89a8576e8fa94436ad5eec5f15611831",
            "placeholder": "​",
            "style": "IPY_MODEL_1cf54886598248dfa931d23a8e44c0b8",
            "value": " 570/570 [00:00&lt;00:00, 72.0kB/s]"
          }
        },
        "0c814c629d8d4c1cb801873f35158954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eb2161de6f94cf0bd94d46c3f5c9687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5d94f21d9a4c41ae48f647f94c1448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d684a312c7c42c69c48936a2a37b3b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3383527d075940d289414108a5a619cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89a8576e8fa94436ad5eec5f15611831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cf54886598248dfa931d23a8e44c0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee3a124ba79340e98b982020e3229959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b73dc1f669c446beb8bc66063e8a1eb5",
              "IPY_MODEL_fa573a4926ba4ba5a04644dc2d133e13",
              "IPY_MODEL_208c94a989a24b1fa27f100dcc00b212"
            ],
            "layout": "IPY_MODEL_1700f383d6c44f19ae35a17b03bb9af6"
          }
        },
        "b73dc1f669c446beb8bc66063e8a1eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb762603d354d86be9b87438de054fe",
            "placeholder": "​",
            "style": "IPY_MODEL_a9ce27c309a041a19a11c4bdbb203845",
            "value": "model.safetensors: 100%"
          }
        },
        "fa573a4926ba4ba5a04644dc2d133e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c128e1f591f480eb2f602d277eba18e",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf984768516f4a9badef12f7ce0c0163",
            "value": 440449768
          }
        },
        "208c94a989a24b1fa27f100dcc00b212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71d841db759e44aaa3b53e5882181371",
            "placeholder": "​",
            "style": "IPY_MODEL_4d47824c9a5c41469ebdcad4ea47e357",
            "value": " 440M/440M [00:01&lt;00:00, 243MB/s]"
          }
        },
        "1700f383d6c44f19ae35a17b03bb9af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb762603d354d86be9b87438de054fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ce27c309a041a19a11c4bdbb203845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c128e1f591f480eb2f602d277eba18e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf984768516f4a9badef12f7ce0c0163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71d841db759e44aaa3b53e5882181371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d47824c9a5c41469ebdcad4ea47e357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfpMUaUBdtlp",
        "outputId": "a72e2a45-9834-4479-b449-a5602a29e7ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GptUUowJoGQ2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker('fr_FR')\n",
        "\n",
        "# Mots-clés tendance (exemples 2024)\n",
        "mots_cles = [\n",
        "    \"#IA\", \"#ChatGPT\", \"#Ukraine\", \"#Euro2024\", \"#Climate\",\n",
        "    \"#Tesla\", \"#Apple\", \"#Metaverse\", \"#NFT\", \"#Crypto\",\n",
        "    \"#PS6\", \"#Netflix\", \"#StrangerThings\", \"#ElonMusk\", \"#Zidane\"\n",
        "]\n",
        "\n",
        "# Génération de 200 tweets fictifs\n",
        "tweets = []\n",
        "for _ in range(2000):\n",
        "    tweet = {\n",
        "        \"text\": fake.sentence() + \" \" + random.choice(mots_cles),\n",
        "        \"likes\": random.randint(0, 5000),  # Likes aléatoires\n",
        "        \"date\": fake.date_this_year()\n",
        "    }\n",
        "    tweets.append(tweet)\n",
        "\n",
        "df = pd.DataFrame(tweets)\n",
        "df[\"viral\"] = (df[\"likes\"] >= 1000).astype(int)  # 1 si viral, 0 sinon\n",
        "\n",
        "# Sauvegarde en CSV\n",
        "df.to_csv(\"tweets_viraux2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"tweets_viraux2.csv\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9Re4aeqe0PD",
        "outputId": "1c45b209-8bbf-44b2-b14a-a56dad621b90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    2000 non-null   object\n",
            " 1   likes   2000 non-null   int64 \n",
            " 2   date    2000 non-null   object\n",
            " 3   viral   2000 non-null   int64 \n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 62.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "# Extraire les hashtags\n",
        "df['hashtags'] = df['text'].apply(lambda x: re.findall(r'#\\w+', x))"
      ],
      "metadata": {
        "id": "2q9ZZQZWhI6m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_exploded = df.explode('hashtags')"
      ],
      "metadata": {
        "id": "ZUVaZKvihUdV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_hashtags = df_exploded.groupby('hashtags')['likes'].agg(\n",
        "    ['count', 'mean', 'median', 'max']\n",
        ").reset_index().sort_values('count', ascending=False)\n",
        "\n",
        "# Renommer les colonnes\n",
        "stats_hashtags.columns = ['Hashtag', 'Nombre de tweets', 'Likes moyens', 'Likes médians', 'Likes max']"
      ],
      "metadata": {
        "id": "snGGpGYHhWfY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stats_hashtags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frePMiBBhgfK",
        "outputId": "984c9831-a967-43f9-c5d8-f05b066b7549"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Hashtag  Nombre de tweets  Likes moyens  Likes médians  Likes max\n",
            "10             #PS6               145   2462.675862         2506.0       4997\n",
            "11  #StrangerThings               145   2470.772414         2711.0       4971\n",
            "13         #Ukraine               143   2522.076923         2521.0       4868\n",
            "5         #Euro2024               142   2532.098592         2520.0       4995\n",
            "3           #Crypto               140   2544.192857         2475.0       4987\n",
            "2          #Climate               137   2639.000000         2803.0       4994\n",
            "7        #Metaverse               135   2502.807407         2540.0       4972\n",
            "6               #IA               133   2444.601504         2433.0       4898\n",
            "8              #NFT               131   2385.000000         2307.0       4977\n",
            "14          #Zidane               130   2719.953846         2694.0       4992\n",
            "1          #ChatGPT               128   2537.328125         2498.5       4982\n",
            "12           #Tesla               128   2574.343750         2549.0       4918\n",
            "0            #Apple               122   2512.795082         2435.0       5000\n",
            "9          #Netflix               121   2538.239669         2451.0       4947\n",
            "4         #ElonMusk               120   2174.741667         1917.5       4924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"Statistiques des Hashtags\")\n",
        "st.dataframe(stats_hashtags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6l7r_0cjUEF",
        "outputId": "5f8d3295-5725-4a5c-facc-13e4ebb0921c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.44.1 watchdog-6.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-24 19:38:19.490 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 19:38:19.615 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-04-24 19:38:19.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 19:38:19.652 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 19:38:19.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOqR_T5FjgUj",
        "outputId": "3f0c0d88-4df1-4863-979e-cd2705055ba5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0OGE1evnFpz",
        "outputId": "01fbc951-cf26-4913-d5a8-8b3bf2969b57"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Charger le tokenizer et le modèle pré-entraîné\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # 2 classes : viral ou non"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "3cee56ccea244fbdb90c8c12ca8c31e0",
            "07e00e9ff1de494fb4c2af9f4fa1a172",
            "960148996d8140ec9348236eff18c83b",
            "808aa02bbbf7469799a63d2d997ededf",
            "3ed116b41fc644d9b3f2ae414bf073ac",
            "282b24f5b2924cf6a3f0fc8364d6186a",
            "f820952b20c449c79b2c6e86bf586156",
            "0ab8030100af40e29b4d654cb6d6aaac",
            "b0eaef979ef547dfa71693a83c9aa877",
            "a1719717c8ff41c68f56bb011b8eda8c",
            "8c622109de814c9486c37c2a92fc5a6b",
            "f89f12e72e9649caad35020afe44ecdc",
            "1e5d54acf3d046409c5c17c6e11f13d7",
            "b9ca3b3642a0417b93017099c685fbee",
            "770f0a2dbcd74fd0a57d9ae80eda4409",
            "60dd58759dda45f48fbf111dc0b30ffc",
            "36b1f47c3bb0463c81e86bfb9ecef7cf",
            "66300d4af5984221866ba2811d1dbc8a",
            "d8224a274ff14140ba28622277eb229c",
            "d7d6f31c3fdb43779ffc39c6273a5e00",
            "a5840d6b15d64f93bacc65c4af9c6ffe",
            "c5bb20c54c034eb199017a07af385f32",
            "c09edb6dfab5492e91d0227063cbeef6",
            "5ef63ccab6f3418288b9599d5ae218b9",
            "80315584e3f9402d875a34faea743a96",
            "dcb4427ce06c483ca55b570276eb8f61",
            "bda660faa6a34818b3061b01cfca9256",
            "5fb5c565374048758a084f2cfd3cff3f",
            "0e56dc25d06842909c0112cc4fc88950",
            "9cf7fcb785a541b2a309278b6ce28c12",
            "552e8714139047e787ed364d40f74885",
            "ea3c0b8a614e4b0cada981d66740a1f3",
            "204f26920dd44cbeb4459086fae83a74",
            "971583f22e5b413a9a0eed60daa5ef61",
            "261f9fb870b84462ba5732ca6e7a8022",
            "3f8f7ecf1b1e4fd0b457f61e51b7c9c4",
            "aa54731512744c2fa15585448ab8a6c7",
            "0c814c629d8d4c1cb801873f35158954",
            "3eb2161de6f94cf0bd94d46c3f5c9687",
            "7f5d94f21d9a4c41ae48f647f94c1448",
            "2d684a312c7c42c69c48936a2a37b3b4",
            "3383527d075940d289414108a5a619cb",
            "89a8576e8fa94436ad5eec5f15611831",
            "1cf54886598248dfa931d23a8e44c0b8",
            "ee3a124ba79340e98b982020e3229959",
            "b73dc1f669c446beb8bc66063e8a1eb5",
            "fa573a4926ba4ba5a04644dc2d133e13",
            "208c94a989a24b1fa27f100dcc00b212",
            "1700f383d6c44f19ae35a17b03bb9af6",
            "2eb762603d354d86be9b87438de054fe",
            "a9ce27c309a041a19a11c4bdbb203845",
            "6c128e1f591f480eb2f602d277eba18e",
            "bf984768516f4a9badef12f7ce0c0163",
            "71d841db759e44aaa3b53e5882181371",
            "4d47824c9a5c41469ebdcad4ea47e357"
          ]
        },
        "id": "DBiUXmtIpHyF",
        "outputId": "0e9793f6-bea5-4189-fccb-53a3a2ec61b7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cee56ccea244fbdb90c8c12ca8c31e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f89f12e72e9649caad35020afe44ecdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c09edb6dfab5492e91d0227063cbeef6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "971583f22e5b413a9a0eed60daa5ef61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee3a124ba79340e98b982020e3229959"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_tweet(tweet, max_len=128):\n",
        "    return tokenizer.encode_plus(\n",
        "        tweet,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "# Exemple\n",
        "tweet = \"This AI news is amazing! #ArtificialIntelligence\"\n",
        "inputs = tokenize_tweet(tweet)"
      ],
      "metadata": {
        "id": "kH6TsDcbp2HM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "source": [
        "import re\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Supprime les hashtags, les mentions et les caractères spéciaux du texte.\"\"\"\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text)  # Supprime les mentions\n",
        "    text = re.sub(r'#', '', text)  # Supprime le symbole hashtag\n",
        "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)  # Supprime les caractères spéciaux\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Supprime les espaces supplémentaires\n",
        "    return text\n",
        "\n",
        "df['text_clean'] = df['text'].apply(clean_text)  # Applique la fonction de nettoyage à la colonne 'text'\n",
        "\n",
        "# Maintenant, vous pouvez procéder au train_test_split :\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df['text_clean'], df['viral'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "RAkN2ez0qfis"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # import the torch module\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "7UeKXBc41bPe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "8PcU2suiykhO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi  # Vérifiez que le GPU est utilisé et la mémoire libre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POSqox47xnr5",
        "outputId": "4011c71a-26e8-4cb8-c730-aac6641203eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 24 19:39:57 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0             48W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UQvuZc9MqZb",
        "outputId": "042b4aa4-c7d9-4e3d-dcfe-19cb3d3094ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU disponible: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Lance une opération lourde pour tester le GPU\n",
        "x = torch.randn(10000, 10000).to(device)\n",
        "y = torch.matmul(x, x)\n",
        "\n",
        "print(\"Opération terminée sur :\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRifBW-lM8O7",
        "outputId": "5b7c4739-f854-4436-8071-60f0fb7ec82c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opération terminée sur : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] # Make sure you install with torch support\n",
        "# Importations\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "\n",
        "\n",
        "\n",
        "# 1. Chargement et prétraitement des données\n",
        "df = pd.read_csv(\"tweets_viraux2.csv\")\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Nettoie le texte des mentions, hashtags et caractères spéciaux\"\"\"\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text)  # Supprime les mentions\n",
        "    text = re.sub(r'#', '', text)  # Supprime les hashtags\n",
        "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)  # Supprime les caractères spéciaux\n",
        "    return re.sub(r'\\s+', ' ', text).strip().lower()  # Espaces et minuscules\n",
        "\n",
        "df['text_clean'] = df['text'].apply(clean_text)\n",
        "\n",
        "# 2. Split des données\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df['text_clean'], df['viral'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Tokenisation globale (optimisée)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_encodings = tokenizer(\n",
        "    X_train.tolist(),\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    max_length=128,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "val_encodings = tokenizer(\n",
        "    X_val.tolist(),\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    max_length=128,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# 4. Préparation des DataLoaders\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_dataset = TensorDataset(\n",
        "    train_encodings['input_ids'],\n",
        "    train_encodings['attention_mask'],\n",
        "    torch.tensor(y_train.values)\n",
        ")\n",
        "val_dataset = TensorDataset(\n",
        "    val_encodings['input_ids'],\n",
        "    val_encodings['attention_mask'],\n",
        "    torch.tensor(y_val.values)\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "# 5. Initialisation du modèle\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5) # Use AdamW from transformers.optimization\n",
        "\n",
        "# ==== NOUVEAU CODE À COPIER ====\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# A. Calcul des poids pour rééquilibrer les classes\n",
        "class_counts = df['viral'].value_counts().to_list()\n",
        "weights = torch.tensor([1.0/class_counts[0], 1.0/class_counts[1]], device=device)\n",
        "\n",
        "# B. Sampler pondéré\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=[weights[lab] for lab in y_train],\n",
        "    num_samples=len(y_train),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# C. DataLoader avec sampler\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    sampler=sampler,  # Remplace shuffle=True\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# D. Loss et optimizer\n",
        "criterion = CrossEntropyLoss(weight=weights)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# E. Boucle d'entraînement améliorée\n",
        "for epoch in range(5):  # 5 epochs maintenant\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, masks, labels = [x.to(device) for x in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "        loss = criterion(outputs.logits, labels)  # Loss pondérée\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Évaluation\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs, masks, labels = [x.to(device) for x in batch]\n",
        "            outputs = model(inputs, attention_mask=masks)\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Affichage des métriques\n",
        "    print(f\"\\nEpoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}\")\n",
        "    print(classification_report(\n",
        "        all_labels,\n",
        "        all_preds,\n",
        "        target_names=['Non Viral', 'Viral'],\n",
        "        zero_division=0\n",
        "    ))\n",
        "\n",
        "# Sauvegarde\n",
        "torch.save(model.state_dict(), 'bert_balanced.pth')\n",
        "# ==== FIN DU CODE À COPIER ====\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl3ghzpJKQDM",
        "outputId": "ce2d0ba3-118e-4418-8eb2-2b9956249a37"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 - Loss: 0.1067\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non Viral       0.00      0.00      0.00        87\n",
            "       Viral       0.78      1.00      0.88       313\n",
            "\n",
            "    accuracy                           0.78       400\n",
            "   macro avg       0.39      0.50      0.44       400\n",
            "weighted avg       0.61      0.78      0.69       400\n",
            "\n",
            "\n",
            "Epoch 2 - Loss: 0.0724\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non Viral       0.00      0.00      0.00        87\n",
            "       Viral       0.78      1.00      0.88       313\n",
            "\n",
            "    accuracy                           0.78       400\n",
            "   macro avg       0.39      0.50      0.44       400\n",
            "weighted avg       0.61      0.78      0.69       400\n",
            "\n",
            "\n",
            "Epoch 3 - Loss: 0.0765\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non Viral       0.00      0.00      0.00        87\n",
            "       Viral       0.78      1.00      0.88       313\n",
            "\n",
            "    accuracy                           0.78       400\n",
            "   macro avg       0.39      0.50      0.44       400\n",
            "weighted avg       0.61      0.78      0.69       400\n",
            "\n",
            "\n",
            "Epoch 4 - Loss: 0.0778\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non Viral       0.00      0.00      0.00        87\n",
            "       Viral       0.78      1.00      0.88       313\n",
            "\n",
            "    accuracy                           0.78       400\n",
            "   macro avg       0.39      0.50      0.44       400\n",
            "weighted avg       0.61      0.78      0.69       400\n",
            "\n",
            "\n",
            "Epoch 5 - Loss: 0.0831\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non Viral       0.00      0.00      0.00        87\n",
            "       Viral       0.78      1.00      0.88       313\n",
            "\n",
            "    accuracy                           0.78       400\n",
            "   macro avg       0.39      0.50      0.44       400\n",
            "weighted avg       0.61      0.78      0.69       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importations supplémentaires nécessaires\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# 1. Rééquilibrage des classes\n",
        "print(\"Distribution originale :\")\n",
        "print(df['viral'].value_counts())\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(\n",
        "    df[['text_clean']],\n",
        "    df['viral']\n",
        ")\n",
        "\n",
        "# 2. Nouveau split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_resampled['text_clean'],\n",
        "    y_resampled,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 3. Réinitialisation du modèle\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "# 4. Implémentation corrigée de FocalLoss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "        return loss.mean()\n",
        "\n",
        "# 5. Initialisation des composants d'entraînement\n",
        "criterion = FocalLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# 6. Tokenisation des données rééquilibrées\n",
        "train_encodings = tokenizer(\n",
        "    X_train.tolist(),\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    max_length=128,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "val_encodings = tokenizer(\n",
        "    X_val.tolist(),\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    max_length=128,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# 7. Préparation des DataLoaders\n",
        "train_dataset = TensorDataset(\n",
        "    train_encodings['input_ids'],\n",
        "    train_encodings['attention_mask'],\n",
        "    torch.tensor(y_train.values)\n",
        ")\n",
        "val_dataset = TensorDataset(\n",
        "    val_encodings['input_ids'],\n",
        "    val_encodings['attention_mask'],\n",
        "    torch.tensor(y_val.values)\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "# 8. Boucle d'entraînement\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, masks, labels = [x.to(device) for x in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=masks)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Évaluation\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs, masks, labels = [x.to(device) for x in batch]\n",
        "            outputs = model(inputs, attention_mask=masks)\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}\")\n",
        "    print(classification_report(\n",
        "        all_labels,\n",
        "        all_preds,\n",
        "        target_names=['Non Viral', 'Viral'],\n",
        "        zero_division=0\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzWyKMNyWYk9",
        "outputId": "6203d1e4-efa7-48f8-8f79-efc6896c7079"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution originale :\n",
            "viral\n",
            "1    1600\n",
            "0     400\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Epoch 1 - Loss: 0.0448\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non Viral       0.57      0.60      0.58       306\n",
            "       Viral       0.61      0.59      0.60       334\n",
            "\n",
            "    accuracy                           0.59       640\n",
            "   macro avg       0.59      0.59      0.59       640\n",
            "weighted avg       0.59      0.59      0.59       640\n",
            "\n",
            "\n",
            "Epoch 2 - Loss: 0.0421\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non Viral       0.85      0.37      0.51       306\n",
            "       Viral       0.62      0.94      0.75       334\n",
            "\n",
            "    accuracy                           0.67       640\n",
            "   macro avg       0.73      0.65      0.63       640\n",
            "weighted avg       0.73      0.67      0.64       640\n",
            "\n",
            "\n",
            "Epoch 3 - Loss: 0.0329\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non Viral       0.68      0.87      0.77       306\n",
            "       Viral       0.84      0.63      0.72       334\n",
            "\n",
            "    accuracy                           0.74       640\n",
            "   macro avg       0.76      0.75      0.74       640\n",
            "weighted avg       0.77      0.74      0.74       640\n",
            "\n",
            "\n",
            "Epoch 4 - Loss: 0.0201\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non Viral       0.92      0.80      0.85       306\n",
            "       Viral       0.83      0.93      0.88       334\n",
            "\n",
            "    accuracy                           0.87       640\n",
            "   macro avg       0.88      0.87      0.87       640\n",
            "weighted avg       0.87      0.87      0.87       640\n",
            "\n",
            "\n",
            "Epoch 5 - Loss: 0.0106\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non Viral       0.90      0.93      0.92       306\n",
            "       Viral       0.94      0.90      0.92       334\n",
            "\n",
            "    accuracy                           0.92       640\n",
            "   macro avg       0.92      0.92      0.92       640\n",
            "weighted avg       0.92      0.92      0.92       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21ugOheOLht3",
        "outputId": "effa1f4f-ec6d-45e0-af1b-ec091530b398"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] # Assurez-vous d'installer avec le support torch\n",
        "# Importations\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig # Importez AutoConfig ici\n",
        "from torch.optim import AdamW\n",
        "import os # Import the os module\n",
        "\n",
        "\n",
        "# 1. Fonction de nettoyage (doit être définie avant le chargement)\n",
        "def clean_text(text):\n",
        "    \"\"\"Fonction de nettoyage des tweets\"\"\"\n",
        "    text = re.sub(r'@\\w+|#|http\\S+|[^\\w\\s]', '', text.lower())\n",
        "    return text.strip()\n",
        "\n",
        "# 2. Localisation du fichier de poids\n",
        "# Spécifiez le chemin correct pour votre fichier .pth\n",
        "WEIGHTS_PATH = \"bert_balanced.pth\"  # ou le nom de votre fichier de modèle sauvegardé\n",
        "\n",
        "# Vérifiez si le fichier existe, déclenchez FileNotFoundError s'il n'est pas trouvé\n",
        "if not os.path.exists(WEIGHTS_PATH):\n",
        "    raise FileNotFoundError(f\"Aucun fichier .pth trouvé à l'emplacement : {WEIGHTS_PATH}. Vérifiez votre sauvegarde.\")\n",
        "\n",
        "print(f\"Chargement des poids depuis : {WEIGHTS_PATH}\")\n",
        "\n",
        "# 3. Configuration du modèle\n",
        "MODEL_PATH = \"bert_streamlit\"\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "# 4. Chargement sécurisé avec gestion des erreurs\n",
        "try:\n",
        "    # Autorisation explicite de la fonction clean_text\n",
        "    with torch.serialization.safe_globals([clean_text]):\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Chargement du modèle de base\n",
        "        model = BertForSequenceClassification.from_pretrained(\n",
        "            'bert-base-uncased',\n",
        "            num_labels=2\n",
        "        ).to(device)\n",
        "\n",
        "        # Chargement des poids avec vérification complète\n",
        "        state_dict = torch.load(\n",
        "            WEIGHTS_PATH,\n",
        "            map_location=device,\n",
        "            # weights_only=False  # Modification ici : retirer weights_only\n",
        "        )\n",
        "\n",
        "        # Vérification de la compatibilité des poids\n",
        "        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "        if missing_keys:\n",
        "            print(f\"Attention : clés manquantes - {missing_keys}\")\n",
        "        if unexpected_keys:\n",
        "            print(f\"Attention : clés inattendues - {unexpected_keys}\")\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Erreur de chargement : {str(e)}\")\n",
        "\n",
        "# 5. Sauvegarde complète\n",
        "model.save_pretrained(MODEL_PATH)\n",
        "BertTokenizer.from_pretrained('bert-base-uncased').save_pretrained(MODEL_PATH)\n",
        "\n",
        "# **Modification ici:** Sauvegarde explicite de l'état du modèle\n",
        "torch.save(model.state_dict(), os.path.join(MODEL_PATH, 'pytorch_model.bin'))\n",
        "\n",
        "# Enregistrement de la configuration du modèle (pour compatibilité)\n",
        "config = AutoConfig.from_pretrained(model.config._name_or_path) # Obtenir la configuration\n",
        "config.save_pretrained(MODEL_PATH) # Sauvegarder la config dans le répertoire\n",
        "\n",
        "# Enregistrez le tokenizer dans le même répertoire.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "tokenizer.save_pretrained(MODEL_PATH)\n",
        "\n",
        "# 6. Métadonnées avec sérialisation sécurisée\n",
        "metadata = {\n",
        "    'class_names': ['Non Viral', 'Viral'],\n",
        "    'max_length': 128,\n",
        "    'clean_text_fn': clean_text  # Référence à la fonction définie plus haut\n",
        "}\n",
        "\n",
        "torch.save(metadata, f\"{MODEL_PATH}/metadata.pth\", _use_new_zipfile_serialization=True)\n",
        "\n",
        "# Vérification finale\n",
        "assert all(os.path.exists(f\"{MODEL_PATH}/{f}\") for f in [\n",
        "    'pytorch_model.bin',\n",
        "    'config.json',\n",
        "    'metadata.pth'\n",
        "]), \"Erreur dans l'export des fichiers\"\n",
        "\n",
        "print(\"✅ Export réussi ! Structure :\")\n",
        "print(\"\\n\".join(sorted(os.listdir(MODEL_PATH))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIuKT5eUVFcJ",
        "outputId": "f9f2f3fe-ed0d-4681-d731-9e1f44b243be"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement des poids depuis : bert_balanced.pth\n",
            "✅ Export réussi ! Structure :\n",
            "config.json\n",
            "metadata.pth\n",
            "model.safetensors\n",
            "pytorch_model.bin\n",
            "special_tokens_map.json\n",
            "tokenizer_config.json\n",
            "vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXPORT COMPLET POUR STREAMLIT\n",
        "import torch\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from safetensors.torch import save_file\n",
        "import re\n",
        "import os\n",
        "\n",
        "# 1. CONFIGURATION\n",
        "MODEL_DIR = \"bert_streamlit_ready\"  # Dossier de sortie\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# 2. CHARGEMENT DU MODÈLE (remplacez par votre chemin)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=2\n",
        ")\n",
        "model.load_state_dict(torch.load('bert_balanced.pth'))  # Vos poids entraînés\n",
        "model.eval()\n",
        "\n",
        "# 3. TOKENIZER\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# 4. FONCTION DE NETTOYAGE (identique à l'entraînement)\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'@\\w+|#|http\\S+|[^\\w\\s]', '', text.lower())\n",
        "    return text.strip()\n",
        "\n",
        "# 5. SAUVEGARDE OPTIMISÉE\n",
        "# Modèle et tokenizer\n",
        "model.save_pretrained(MODEL_DIR)\n",
        "tokenizer.save_pretrained(MODEL_DIR)\n",
        "\n",
        "# Conversion en safetensors (format recommandé)\n",
        "save_file(model.state_dict(), f\"{MODEL_DIR}/model.safetensors\")\n",
        "\n",
        "# Métadonnées\n",
        "torch.save({\n",
        "    'class_names': ['Non Viral', 'Viral'],\n",
        "    'max_length': 128,\n",
        "    'clean_text_fn': clean_text\n",
        "}, f\"{MODEL_DIR}/metadata.pth\")\n",
        "\n",
        "# 6. NETTOYAGE (supprime les doublons)\n",
        "if os.path.exists(f\"{MODEL_DIR}/pytorch_model.bin\"):\n",
        "    os.remove(f\"{MODEL_DIR}/pytorch_model.bin\")\n",
        "\n",
        "# 7. VÉRIFICATION FINALE\n",
        "required_files = [\n",
        "    'config.json',\n",
        "    'model.safetensors',\n",
        "    'tokenizer_config.json',\n",
        "    'special_tokens_map.json',\n",
        "    'vocab.txt',\n",
        "    'metadata.pth'\n",
        "]\n",
        "\n",
        "missing = [f for f in required_files if not os.path.exists(f\"{MODEL_DIR}/{f}\")]\n",
        "assert not missing, f\"Fichiers manquants : {missing}\"\n",
        "\n",
        "print(\"✅ Export réussi ! Structure :\")\n",
        "print(\"\\n\".join(sorted(os.listdir(MODEL_DIR))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWEM4gFNX1Tc",
        "outputId": "60d6fc20-3de7-4d03-e818-ad6e3e2b0c75"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Export réussi ! Structure :\n",
            "config.json\n",
            "metadata.pth\n",
            "model.safetensors\n",
            "special_tokens_map.json\n",
            "tokenizer_config.json\n",
            "vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "import streamlit as st\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import re\n",
        "import os # Import the os module\n",
        "\n",
        "\n",
        "# Configuration\n",
        "MODEL_DIR = \"bert_streamlit_ready\"\n",
        "\n",
        "# Define clean_text function outside of load_model for pickling\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'@\\w+|#|http\\S+|[^\\w\\s]', '', text.lower())\n",
        "    return text.strip()\n",
        "\n",
        "# Fonction de chargement\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    # Tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)\n",
        "\n",
        "    # Métadonnées\n",
        "    # Use safe_globals to allow clean_text\n",
        "    with torch.serialization.safe_globals([clean_text]):\n",
        "        metadata = torch.load(f\"{MODEL_DIR}/metadata.pth\", map_location='cpu')\n",
        "\n",
        "    # Modèle\n",
        "    model = BertForSequenceClassification.from_pretrained(MODEL_DIR, num_labels=2) # Remove state_dict\n",
        "    model.load_state_dict(load_file(f\"{MODEL_DIR}/model.safetensors\")) # Load state dict separately\n",
        "    model.eval()\n",
        "\n",
        "    return model, tokenizer, metadata\n",
        "\n",
        "# Interface\n",
        "st.title(\"🔮 Prédiction de Tweets Viraux\")\n",
        "model, tokenizer, metadata = load_model()\n",
        "\n",
        "user_input = st.text_area(\"Entrez un tweet :\")\n",
        "if st.button(\"Prédire\") and user_input:\n",
        "    # Nettoyage\n",
        "    text = metadata['clean_text_fn'](user_input)\n",
        "\n",
        "    # Tokenisation\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "\n",
        "    # Prédiction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Résultats\n",
        "    viral_prob = probs[0][1].item()\n",
        "    st.metric(\"Probabilité d'être viral\", f\"{viral_prob:.1%}\")\n",
        "\n",
        "    # Jauge visuelle\n",
        "    st.progress(viral_prob)\n",
        "\n",
        "    # Interprétation\n",
        "    threshold = 0.7\n",
        "    if viral_prob > threshold:\n",
        "        st.success(\"🔥 Tweet viral potentiel !\")\n",
        "    else:\n",
        "        st.info(\"💤 Peu susceptible de devenir viral\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBPO4SxOY57L",
        "outputId": "de3c2086-5ba3-4206-aa3f-8a25ecda23f4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-24 20:01:02.496 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.497 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.498 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.499 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.499 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.740 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.741 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.742 Session state does not function when running a script without `streamlit run`\n",
            "2025-04-24 20:01:02.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.744 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.745 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.745 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.746 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.746 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-24 20:01:02.747 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import re\n",
        "import sys\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    MODEL_DIR = \"bert_streamlit_ready\"\n",
        "\n",
        "    @st.cache_resource\n",
        "    def load_model():\n",
        "        model = BertForSequenceClassification.from_pretrained(\n",
        "            MODEL_DIR,\n",
        "            state_dict=load_file(f\"{MODEL_DIR}/model.safetensors\")\n",
        "        )\n",
        "        tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)\n",
        "        metadata = torch.load(f\"{MODEL_DIR}/metadata.pth\", map_location='cpu')\n",
        "        return model, tokenizer, metadata\n",
        "\n",
        "    # Interface\n",
        "    st.title(\"🔮 Prédiction de Tweets Viraux\")\n",
        "    model, tokenizer, metadata = load_model()\n",
        "\n",
        "    user_input = st.text_area(\"Entrez un tweet :\")\n",
        "    if st.button(\"Prédire\") and user_input:\n",
        "        text = metadata['clean_text_fn'](user_input)\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "\n",
        "        viral_prob = probs[0][1].item()\n",
        "        st.metric(\"Probabilité d'être viral\", f\"{viral_prob:.1%}\")\n",
        "        st.progress(viral_prob)\n",
        "\n",
        "        if viral_prob > 0.7:\n",
        "            st.success(\"🔥 Tweet viral potentiel !\")\n",
        "        else:\n",
        "            st.info(\"💤 Peu susceptible de devenir viral\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Solution pour les avertissements\n",
        "    if len(sys.argv) == 1 or sys.argv[1] != \"run\":\n",
        "        print(\"Veuillez exécuter avec : streamlit run app.py\")\n",
        "    else:\n",
        "        main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUFN5P88ZlI9",
        "outputId": "1709191a-405d-4a06-ad34-13d23a413cef"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Veuillez exécuter avec : streamlit run app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import re\n",
        "import sys\n",
        "\n",
        "# Define clean_text function outside of load_model and main for pickling\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'@\\w+|#|http\\S+|[^\\w\\s]', '', text.lower())\n",
        "    return text.strip()\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    MODEL_DIR = \"bert_streamlit_ready\"\n",
        "\n",
        "    # Chargement du modèle\n",
        "    @st.cache_resource\n",
        "    def load_model():\n",
        "        try:\n",
        "            # 1. Load the model structure from the directory\n",
        "            model = BertForSequenceClassification.from_pretrained(MODEL_DIR, num_labels=2)\n",
        "\n",
        "            # 2. Load the state dict\n",
        "            model.load_state_dict(load_file(f\"{MODEL_DIR}/model.safetensors\"))\n",
        "\n",
        "            tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)\n",
        "            # Use safe_globals to allow clean_text when loading metadata\n",
        "            with torch.serialization.safe_globals([clean_text]):\n",
        "                metadata = torch.load(f\"{MODEL_DIR}/metadata.pth\", map_location='cpu')\n",
        "            return model, tokenizer, metadata\n",
        "        except Exception as e:\n",
        "            st.error(f\"Erreur de chargement du modèle : {str(e)}\")\n",
        "            return None, None, None  # Return None values on error\n",
        "\n",
        "    # Interface\n",
        "    st.set_page_config(page_title=\"Prédiction de Tweets Viraux\", layout=\"wide\")\n",
        "    st.title(\"🔮 Prédiction de Tweets Viraux\")\n",
        "\n",
        "    model, tokenizer, metadata = load_model()\n",
        "\n",
        "    # Check if model loaded successfully before proceeding\n",
        "    if model is not None and tokenizer is not None and metadata is not None:\n",
        "        with st.form(\"prediction_form\"):\n",
        "            user_input = st.text_area(\"Entrez un tweet :\")\n",
        "            submitted = st.form_submit_button(\"Prédire\")\n",
        "\n",
        "            if submitted and user_input:\n",
        "                with st.spinner(\"Analyse en cours...\"):\n",
        "                    try:\n",
        "                        # Nettoyage et tokenisation\n",
        "                        text = metadata['clean_text_fn'](user_input)\n",
        "                        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "\n",
        "                        # Prédiction\n",
        "                        with torch.no_grad():\n",
        "                            outputs = model(**inputs)\n",
        "                            probs = torch.softmax(outputs.logits, dim=1)\n",
        "\n",
        "                        # Affichage\n",
        "                        viral_prob = probs[0][1].item()\n",
        "                        st.metric(\"Probabilité d'être viral\", f\"{viral_prob:.1%}\")\n",
        "                        st.progress(viral_prob)\n",
        "\n",
        "                        if viral_prob > 0.7:\n",
        "                            st.success(\"🔥 Tweet viral potentiel !\")\n",
        "                        else:\n",
        "                            st.info(\"💤 Peu susceptible de devenir viral\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Erreur lors de la prédiction : {str(e)}\")\n",
        "    else:\n",
        "        st.error(\"Le modèle n'a pas pu être chargé. Veuillez vérifier les logs d'erreur.\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if \"streamlit\" in sys.modules:\n",
        "        main()\n",
        "    else:\n",
        "        print(\"⚠️ Veuillez exécuter avec : streamlit run app.py\")\n",
        "        print(\"   Ou via Jupyter : !streamlit run app.py\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"✅ Fichier app.py créé avec succès !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H602DFBCcu3d",
        "outputId": "0793f498-55b3-4378-da80-f98544135a85"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier app.py créé avec succès !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import re\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "# Suppression des avertissements Streamlit\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"missing ScriptRunContext\")\n",
        "\n",
        "# Fonction de nettoyage globale (pour la sérialisation)\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'@\\w+|#|http\\S+|[^\\w\\s]', '', text.lower())\n",
        "    return text.strip()\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    MODEL_DIR = \"bert_streamlit_ready\"\n",
        "\n",
        "    # Chargement du modèle avec cache\n",
        "    @st.cache_resource\n",
        "    def load_components():\n",
        "        try:\n",
        "            # Modèle\n",
        "            model = BertForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "            model.load_state_dict(load_file(f\"{MODEL_DIR}/model.safetensors\"))\n",
        "\n",
        "            # Tokenizer\n",
        "            tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)\n",
        "\n",
        "            # Métadonnées avec contexte sécurisé\n",
        "            with torch.serialization.safe_globals([clean_text]):\n",
        "                metadata = torch.load(f\"{MODEL_DIR}/metadata.pth\", map_location='cpu')\n",
        "\n",
        "            return model, tokenizer, metadata\n",
        "        except Exception as e:\n",
        "            st.error(f\"Erreur technique : {str(e)}\")\n",
        "            sys.exit(1)\n",
        "\n",
        "    # Interface\n",
        "    st.set_page_config(\n",
        "        page_title=\"Prédiction de Tweets Viraux\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\"\n",
        "    )\n",
        "\n",
        "    st.title(\"🔮 Analyse de Viralité des Tweets\")\n",
        "    model, tokenizer, metadata = load_components()\n",
        "\n",
        "    # Formulaire de prédiction\n",
        "    with st.form(key=\"prediction_form\"):\n",
        "        tweet = st.text_area(\"Collez votre tweet ici :\", height=150)\n",
        "        submit = st.form_submit_button(\"Analyser\")\n",
        "\n",
        "        if submit and tweet:\n",
        "            with st.spinner(\"Analyse en cours...\"):\n",
        "                try:\n",
        "                    # Prétraitement\n",
        "                    text = clean_text(tweet)\n",
        "                    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "\n",
        "                    # Prédiction\n",
        "                    with torch.no_grad():\n",
        "                        logits = model(**inputs).logits\n",
        "                        proba = torch.softmax(logits, dim=1)[0][1].item()\n",
        "\n",
        "                    # Résultats\n",
        "                    st.metric(\"Score de Viralité\", f\"{proba:.1%}\")\n",
        "                    st.progress(proba)\n",
        "\n",
        "                    # Interprétation\n",
        "                    if proba > 0.75:\n",
        "                        st.balloons()\n",
        "                        st.success(\"🔥 Fort potentiel viral !\")\n",
        "                    elif proba > 0.5:\n",
        "                        st.warning(\"📈 Potentiel viral moyen\")\n",
        "                    else:\n",
        "                        st.info(\"📉 Faible probabilité de viralité\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Erreur d'analyse : {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not st.runtime.exists():\n",
        "        print(\"Usage : streamlit run app.py\")\n",
        "    else:\n",
        "        main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isfcBoaMdWc8",
        "outputId": "7cbf436e-a8e7-4139-e9a1-2a3e7de3aa86"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage : streamlit run app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "WTND6782dpOy"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}